{"ast":null,"code":"// loaders.gl\n// SPDX-License-Identifier: MIT\n// Copyright (c) vis.gl contributors\nimport { MD5Hash } from '@loaders.gl/crypto';\nimport { concatenateArrayBuffers, concatenateArrayBuffersFromArray } from '@loaders.gl/loader-utils';\nimport { makeZipCDHeaderIterator } from \"./parse-zip/cd-file-header.js\";\n/**\n * Reads hash file from buffer and returns it in ready-to-use form\n * @param arrayBuffer - buffer containing hash file\n * @returns Map containing hash and offset\n */\nexport function parseHashTable(arrayBuffer) {\n  const dataView = new DataView(arrayBuffer);\n  const hashMap = {};\n  for (let i = 0; i < arrayBuffer.byteLength; i = i + 24) {\n    const offset = dataView.getBigUint64(i + 16, true);\n    const hash = bufferToHex(arrayBuffer, i, 16);\n    hashMap[hash] = offset;\n  }\n  return hashMap;\n}\nfunction bufferToHex(buffer, start, length) {\n  // buffer is an ArrayBuffer\n  return [...new Uint8Array(buffer, start, length)].map(x => x.toString(16).padStart(2, '0')).join('');\n}\n/**\n * generates hash info from zip files \"central directory\"\n * @param fileProvider - provider of the archive\n * @returns ready to use hash info\n */\nexport async function makeHashTableFromZipHeaders(fileProvider) {\n  const zipCDIterator = makeZipCDHeaderIterator(fileProvider);\n  return getHashTable(zipCDIterator);\n}\n/**\n * creates hash table from file offset iterator\n * @param zipCDIterator iterator to use\n * @returns hash table\n */\nexport async function getHashTable(zipCDIterator) {\n  const md5Hash = new MD5Hash();\n  const textEncoder = new TextEncoder();\n  const hashTable = {};\n  for await (const cdHeader of zipCDIterator) {\n    const filename = cdHeader.fileName.split('\\\\').join('/').toLocaleLowerCase();\n    const arrayBuffer = textEncoder.encode(filename).buffer;\n    const md5 = await md5Hash.hash(arrayBuffer, 'hex');\n    hashTable[md5] = cdHeader.localHeaderOffset;\n  }\n  return hashTable;\n}\n/**\n * creates hash file that later can be added to the SLPK archive\n * @param zipCDIterator iterator to use\n * @returns ArrayBuffer containing hash file\n */\nexport async function composeHashFile(zipCDIterator) {\n  const md5Hash = new MD5Hash();\n  const textEncoder = new TextEncoder();\n  const hashArray = [];\n  for await (const cdHeader of zipCDIterator) {\n    let filename = cdHeader.fileName.split('\\\\').join('/');\n    // I3S edge case. All files should be lower case by spec. However, ArcGIS\n    // and official i3s_converter https://github.com/Esri/i3s-spec/blob/master/i3s_converter/i3s_converter_ReadMe.md\n    // expect `3dSceneLayer.json.gz` in camel case\n    if (filename !== '3dSceneLayer.json.gz') {\n      filename = filename.toLocaleLowerCase();\n    }\n    const arrayBuffer = textEncoder.encode(filename).buffer;\n    const md5 = await md5Hash.hash(arrayBuffer, 'hex');\n    hashArray.push(concatenateArrayBuffers(hexStringToBuffer(md5), bigintToBuffer(cdHeader.localHeaderOffset)));\n  }\n  const bufferArray = hashArray.sort(compareHashes);\n  return concatenateArrayBuffersFromArray(bufferArray);\n}\n/**\n * Function to compare md5 hashes according to https://github.com/Esri/i3s-spec/blob/master/docs/2.0/slpk_hashtable.pcsl.md\n * @param arrA first hash to compare\n * @param arrB second hash to compare\n * @returns 0 if equal, negative number if a<b, pozitive if a>b\n */\nfunction compareHashes(arrA, arrB) {\n  const a = new BigUint64Array(arrA);\n  const b = new BigUint64Array(arrB);\n  return Number(a[0] === b[0] ? a[1] - b[1] : a[0] - b[0]);\n}\n/**\n * converts hex string to buffer\n * @param str hex string to convert\n * @returns conversion result\n */\nfunction hexStringToBuffer(str) {\n  const byteArray = str.match(/../g)?.map(h => parseInt(h, 16));\n  return new Uint8Array(byteArray ?? new Array(16)).buffer;\n}\n/**\n * converts bigint to buffer\n * @param n bigint to convert\n * @returns convertion result\n */\nfunction bigintToBuffer(n) {\n  return new BigUint64Array([n]).buffer;\n}","map":{"version":3,"names":["MD5Hash","concatenateArrayBuffers","concatenateArrayBuffersFromArray","makeZipCDHeaderIterator","parseHashTable","arrayBuffer","dataView","DataView","hashMap","i","byteLength","offset","getBigUint64","hash","bufferToHex","buffer","start","length","Uint8Array","map","x","toString","padStart","join","makeHashTableFromZipHeaders","fileProvider","zipCDIterator","getHashTable","md5Hash","textEncoder","TextEncoder","hashTable","cdHeader","filename","fileName","split","toLocaleLowerCase","encode","md5","localHeaderOffset","composeHashFile","hashArray","push","hexStringToBuffer","bigintToBuffer","bufferArray","sort","compareHashes","arrA","arrB","a","BigUint64Array","b","Number","str","byteArray","match","h","parseInt","Array","n"],"sources":["C:/Users/jakes/Documents/GitHub/duck-data-flask/duck-data-webpage/node_modules/@loaders.gl/zip/dist/hash-file-utility.js"],"sourcesContent":["// loaders.gl\n// SPDX-License-Identifier: MIT\n// Copyright (c) vis.gl contributors\nimport { MD5Hash } from '@loaders.gl/crypto';\nimport { concatenateArrayBuffers, concatenateArrayBuffersFromArray } from '@loaders.gl/loader-utils';\nimport { makeZipCDHeaderIterator } from \"./parse-zip/cd-file-header.js\";\n/**\n * Reads hash file from buffer and returns it in ready-to-use form\n * @param arrayBuffer - buffer containing hash file\n * @returns Map containing hash and offset\n */\nexport function parseHashTable(arrayBuffer) {\n    const dataView = new DataView(arrayBuffer);\n    const hashMap = {};\n    for (let i = 0; i < arrayBuffer.byteLength; i = i + 24) {\n        const offset = dataView.getBigUint64(i + 16, true);\n        const hash = bufferToHex(arrayBuffer, i, 16);\n        hashMap[hash] = offset;\n    }\n    return hashMap;\n}\nfunction bufferToHex(buffer, start, length) {\n    // buffer is an ArrayBuffer\n    return [...new Uint8Array(buffer, start, length)]\n        .map((x) => x.toString(16).padStart(2, '0'))\n        .join('');\n}\n/**\n * generates hash info from zip files \"central directory\"\n * @param fileProvider - provider of the archive\n * @returns ready to use hash info\n */\nexport async function makeHashTableFromZipHeaders(fileProvider) {\n    const zipCDIterator = makeZipCDHeaderIterator(fileProvider);\n    return getHashTable(zipCDIterator);\n}\n/**\n * creates hash table from file offset iterator\n * @param zipCDIterator iterator to use\n * @returns hash table\n */\nexport async function getHashTable(zipCDIterator) {\n    const md5Hash = new MD5Hash();\n    const textEncoder = new TextEncoder();\n    const hashTable = {};\n    for await (const cdHeader of zipCDIterator) {\n        const filename = cdHeader.fileName.split('\\\\').join('/').toLocaleLowerCase();\n        const arrayBuffer = textEncoder.encode(filename).buffer;\n        const md5 = await md5Hash.hash(arrayBuffer, 'hex');\n        hashTable[md5] = cdHeader.localHeaderOffset;\n    }\n    return hashTable;\n}\n/**\n * creates hash file that later can be added to the SLPK archive\n * @param zipCDIterator iterator to use\n * @returns ArrayBuffer containing hash file\n */\nexport async function composeHashFile(zipCDIterator) {\n    const md5Hash = new MD5Hash();\n    const textEncoder = new TextEncoder();\n    const hashArray = [];\n    for await (const cdHeader of zipCDIterator) {\n        let filename = cdHeader.fileName.split('\\\\').join('/');\n        // I3S edge case. All files should be lower case by spec. However, ArcGIS\n        // and official i3s_converter https://github.com/Esri/i3s-spec/blob/master/i3s_converter/i3s_converter_ReadMe.md\n        // expect `3dSceneLayer.json.gz` in camel case\n        if (filename !== '3dSceneLayer.json.gz') {\n            filename = filename.toLocaleLowerCase();\n        }\n        const arrayBuffer = textEncoder.encode(filename).buffer;\n        const md5 = await md5Hash.hash(arrayBuffer, 'hex');\n        hashArray.push(concatenateArrayBuffers(hexStringToBuffer(md5), bigintToBuffer(cdHeader.localHeaderOffset)));\n    }\n    const bufferArray = hashArray.sort(compareHashes);\n    return concatenateArrayBuffersFromArray(bufferArray);\n}\n/**\n * Function to compare md5 hashes according to https://github.com/Esri/i3s-spec/blob/master/docs/2.0/slpk_hashtable.pcsl.md\n * @param arrA first hash to compare\n * @param arrB second hash to compare\n * @returns 0 if equal, negative number if a<b, pozitive if a>b\n */\nfunction compareHashes(arrA, arrB) {\n    const a = new BigUint64Array(arrA);\n    const b = new BigUint64Array(arrB);\n    return Number(a[0] === b[0] ? a[1] - b[1] : a[0] - b[0]);\n}\n/**\n * converts hex string to buffer\n * @param str hex string to convert\n * @returns conversion result\n */\nfunction hexStringToBuffer(str) {\n    const byteArray = str.match(/../g)?.map((h) => parseInt(h, 16));\n    return new Uint8Array(byteArray ?? new Array(16)).buffer;\n}\n/**\n * converts bigint to buffer\n * @param n bigint to convert\n * @returns convertion result\n */\nfunction bigintToBuffer(n) {\n    return new BigUint64Array([n]).buffer;\n}\n"],"mappings":"AAAA;AACA;AACA;AACA,SAASA,OAAO,QAAQ,oBAAoB;AAC5C,SAASC,uBAAuB,EAAEC,gCAAgC,QAAQ,0BAA0B;AACpG,SAASC,uBAAuB,QAAQ,+BAA+B;AACvE;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,cAAcA,CAACC,WAAW,EAAE;EACxC,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAACF,WAAW,CAAC;EAC1C,MAAMG,OAAO,GAAG,CAAC,CAAC;EAClB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,WAAW,CAACK,UAAU,EAAED,CAAC,GAAGA,CAAC,GAAG,EAAE,EAAE;IACpD,MAAME,MAAM,GAAGL,QAAQ,CAACM,YAAY,CAACH,CAAC,GAAG,EAAE,EAAE,IAAI,CAAC;IAClD,MAAMI,IAAI,GAAGC,WAAW,CAACT,WAAW,EAAEI,CAAC,EAAE,EAAE,CAAC;IAC5CD,OAAO,CAACK,IAAI,CAAC,GAAGF,MAAM;EAC1B;EACA,OAAOH,OAAO;AAClB;AACA,SAASM,WAAWA,CAACC,MAAM,EAAEC,KAAK,EAAEC,MAAM,EAAE;EACxC;EACA,OAAO,CAAC,GAAG,IAAIC,UAAU,CAACH,MAAM,EAAEC,KAAK,EAAEC,MAAM,CAAC,CAAC,CAC5CE,GAAG,CAAEC,CAAC,IAAKA,CAAC,CAACC,QAAQ,CAAC,EAAE,CAAC,CAACC,QAAQ,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,CAC3CC,IAAI,CAAC,EAAE,CAAC;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAeC,2BAA2BA,CAACC,YAAY,EAAE;EAC5D,MAAMC,aAAa,GAAGvB,uBAAuB,CAACsB,YAAY,CAAC;EAC3D,OAAOE,YAAY,CAACD,aAAa,CAAC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAeC,YAAYA,CAACD,aAAa,EAAE;EAC9C,MAAME,OAAO,GAAG,IAAI5B,OAAO,CAAC,CAAC;EAC7B,MAAM6B,WAAW,GAAG,IAAIC,WAAW,CAAC,CAAC;EACrC,MAAMC,SAAS,GAAG,CAAC,CAAC;EACpB,WAAW,MAAMC,QAAQ,IAAIN,aAAa,EAAE;IACxC,MAAMO,QAAQ,GAAGD,QAAQ,CAACE,QAAQ,CAACC,KAAK,CAAC,IAAI,CAAC,CAACZ,IAAI,CAAC,GAAG,CAAC,CAACa,iBAAiB,CAAC,CAAC;IAC5E,MAAM/B,WAAW,GAAGwB,WAAW,CAACQ,MAAM,CAACJ,QAAQ,CAAC,CAAClB,MAAM;IACvD,MAAMuB,GAAG,GAAG,MAAMV,OAAO,CAACf,IAAI,CAACR,WAAW,EAAE,KAAK,CAAC;IAClD0B,SAAS,CAACO,GAAG,CAAC,GAAGN,QAAQ,CAACO,iBAAiB;EAC/C;EACA,OAAOR,SAAS;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAeS,eAAeA,CAACd,aAAa,EAAE;EACjD,MAAME,OAAO,GAAG,IAAI5B,OAAO,CAAC,CAAC;EAC7B,MAAM6B,WAAW,GAAG,IAAIC,WAAW,CAAC,CAAC;EACrC,MAAMW,SAAS,GAAG,EAAE;EACpB,WAAW,MAAMT,QAAQ,IAAIN,aAAa,EAAE;IACxC,IAAIO,QAAQ,GAAGD,QAAQ,CAACE,QAAQ,CAACC,KAAK,CAAC,IAAI,CAAC,CAACZ,IAAI,CAAC,GAAG,CAAC;IACtD;IACA;IACA;IACA,IAAIU,QAAQ,KAAK,sBAAsB,EAAE;MACrCA,QAAQ,GAAGA,QAAQ,CAACG,iBAAiB,CAAC,CAAC;IAC3C;IACA,MAAM/B,WAAW,GAAGwB,WAAW,CAACQ,MAAM,CAACJ,QAAQ,CAAC,CAAClB,MAAM;IACvD,MAAMuB,GAAG,GAAG,MAAMV,OAAO,CAACf,IAAI,CAACR,WAAW,EAAE,KAAK,CAAC;IAClDoC,SAAS,CAACC,IAAI,CAACzC,uBAAuB,CAAC0C,iBAAiB,CAACL,GAAG,CAAC,EAAEM,cAAc,CAACZ,QAAQ,CAACO,iBAAiB,CAAC,CAAC,CAAC;EAC/G;EACA,MAAMM,WAAW,GAAGJ,SAAS,CAACK,IAAI,CAACC,aAAa,CAAC;EACjD,OAAO7C,gCAAgC,CAAC2C,WAAW,CAAC;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASE,aAAaA,CAACC,IAAI,EAAEC,IAAI,EAAE;EAC/B,MAAMC,CAAC,GAAG,IAAIC,cAAc,CAACH,IAAI,CAAC;EAClC,MAAMI,CAAC,GAAG,IAAID,cAAc,CAACF,IAAI,CAAC;EAClC,OAAOI,MAAM,CAACH,CAAC,CAAC,CAAC,CAAC,KAAKE,CAAC,CAAC,CAAC,CAAC,GAAGF,CAAC,CAAC,CAAC,CAAC,GAAGE,CAAC,CAAC,CAAC,CAAC,GAAGF,CAAC,CAAC,CAAC,CAAC,GAAGE,CAAC,CAAC,CAAC,CAAC,CAAC;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,SAAST,iBAAiBA,CAACW,GAAG,EAAE;EAC5B,MAAMC,SAAS,GAAGD,GAAG,CAACE,KAAK,CAAC,KAAK,CAAC,EAAErC,GAAG,CAAEsC,CAAC,IAAKC,QAAQ,CAACD,CAAC,EAAE,EAAE,CAAC,CAAC;EAC/D,OAAO,IAAIvC,UAAU,CAACqC,SAAS,IAAI,IAAII,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC5C,MAAM;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,SAAS6B,cAAcA,CAACgB,CAAC,EAAE;EACvB,OAAO,IAAIT,cAAc,CAAC,CAACS,CAAC,CAAC,CAAC,CAAC7C,MAAM;AACzC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}