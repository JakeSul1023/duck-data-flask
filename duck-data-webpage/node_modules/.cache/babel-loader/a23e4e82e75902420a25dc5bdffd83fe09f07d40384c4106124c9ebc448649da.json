{"ast":null,"code":"// loaders.gl\n// SPDX-License-Identifier: MIT\n// Copyright (c) vis.gl contributors\nimport { isTable, makeBatchFromTable } from '@loaders.gl/schema';\nimport { concatenateArrayBuffersAsync } from '@loaders.gl/loader-utils';\nimport { isLoaderObject } from \"../loader-utils/normalize-loader.js\";\nimport { normalizeOptions } from \"../loader-utils/option-utils.js\";\nimport { getLoaderContext } from \"../loader-utils/loader-context.js\";\nimport { getAsyncIterableFromData } from \"../loader-utils/get-data.js\";\nimport { getResourceUrl } from \"../utils/resource-utils.js\";\nimport { selectLoader } from \"./select-loader.js\";\n// Ensure `parse` is available in context if loader falls back to `parse`\nimport { parse } from \"./parse.js\";\n/**\n * Parses `data` using a specified loader\n * @param data\n * @param loaders\n * @param options\n * @param context\n */\nexport async function parseInBatches(data, loaders, options, context) {\n  const loaderArray = Array.isArray(loaders) ? loaders : undefined;\n  // Signature: parseInBatches(data, options, url) - Uses registered loaders\n  if (!Array.isArray(loaders) && !isLoaderObject(loaders)) {\n    context = undefined; // context not supported in short signature\n    options = loaders;\n    loaders = undefined;\n  }\n  data = await data; // Resolve any promise\n  options = options || {};\n  // Extract a url for auto detection\n  const url = getResourceUrl(data);\n  // Chooses a loader and normalizes it\n  // Note - only uses URL and contentType for streams and iterator inputs\n  const loader = await selectLoader(data, loaders, options);\n  // Note: if options.nothrow was set, it is possible that no loader was found, if so just return null\n  if (!loader) {\n    return [];\n  }\n  // Normalize options\n  options = normalizeOptions(options, loader, loaderArray, url);\n  context = getLoaderContext({\n    url,\n    _parseInBatches: parseInBatches,\n    _parse: parse,\n    loaders: loaderArray\n  }, options, context || null);\n  return await parseWithLoaderInBatches(loader, data, options, context);\n}\n/**\n * Loader has been selected and context has been prepared, see if we need to emit a metadata batch\n */\nasync function parseWithLoaderInBatches(loader, data, options, context) {\n  const outputIterator = await parseToOutputIterator(loader, data, options, context);\n  // Generate metadata batch if requested\n  if (!options.metadata) {\n    return outputIterator;\n  }\n  const metadataBatch = {\n    shape: 'metadata',\n    batchType: 'metadata',\n    metadata: {\n      _loader: loader,\n      _context: context\n    },\n    // Populate with some default fields to avoid crashing\n    data: [],\n    bytesUsed: 0\n  };\n  async function* makeMetadataBatchIterator(iterator) {\n    yield metadataBatch;\n    yield* iterator;\n  }\n  return makeMetadataBatchIterator(outputIterator);\n}\n/**\n * Prep work is done, now it is time to start parsing into an output operator\n * The approach depends on which parse function the loader exposes\n * `parseInBatches` (preferred), `parse` (fallback)\n */\nasync function parseToOutputIterator(loader, data, options, context) {\n  // Get an iterator from the input\n  const inputIterator = await getAsyncIterableFromData(data, options);\n  // Apply any iterator transforms (options.transforms)\n  const transformedIterator = await applyInputTransforms(inputIterator, options?.transforms || []);\n  // If loader supports parseInBatches, we are done\n  if (loader.parseInBatches) {\n    return loader.parseInBatches(transformedIterator, options, context);\n  }\n  return parseChunkInBatches(transformedIterator, loader, options, context);\n}\n// Fallback: load atomically using `parse` concatenating input iterator into single chunk\nasync function* parseChunkInBatches(transformedIterator, loader, options, context) {\n  const arrayBuffer = await concatenateArrayBuffersAsync(transformedIterator);\n  // Call `parse` instead of `loader.parse` to ensure we can call workers etc.\n  const parsedData = await parse(arrayBuffer, loader,\n  // TODO - Hack: supply loaders MIME type to ensure we match it\n  {\n    ...options,\n    mimeType: loader.mimeTypes[0]\n  }, context);\n  // yield a single batch, the output from loader.parse() repackaged as a batch\n  const batch = convertDataToBatch(parsedData, loader);\n  yield batch;\n}\n/**\n * Convert parsed data into a single batch\n * @todo run through batch builder to apply options etc...\n */\nfunction convertDataToBatch(parsedData, loader) {\n  // prettier-ignore\n  const batch = isTable(parsedData) ? makeBatchFromTable(parsedData) : {\n    shape: 'unknown',\n    batchType: 'data',\n    data: parsedData,\n    length: Array.isArray(parsedData) ? parsedData.length : 1\n  };\n  batch.mimeType = loader.mimeTypes[0];\n  return batch;\n}\n/**\n * Create an iterator chain with any transform iterators (crypto, decompression)\n * @param inputIterator\n * @param options\n */\nasync function applyInputTransforms(inputIterator, transforms = []) {\n  let iteratorChain = inputIterator;\n  for await (const transformBatches of transforms) {\n    iteratorChain = transformBatches(iteratorChain);\n  }\n  return iteratorChain;\n}","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}